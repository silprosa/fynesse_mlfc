{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silprosa/fynesse_mlfc/blob/main/_notebooks/03-dataset-joining-practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b-yApA2uJ6z"
      },
      "source": [
        "# Practical 3: Dataset Joining and Access-Assess-Address Framework\n",
        "\n",
        "### Radzim Sendyka\n",
        "\n",
        "### [Neil D. Lawrence](http://inverseprobability.com), University of\n",
        "\n",
        "Cambridge\n",
        "\n",
        "### 2025-09-08"
      ],
      "id": "3b-yApA2uJ6z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haHi8oQRuJ61"
      },
      "source": [
        "**Abstract**: In this lab session we will explore dataset joining\n",
        "techniques, implement the Access-Assess-Address framework in practice,\n",
        "work with the DSAIL Porini camera trap data, and build predictive models\n",
        "for animal sightings."
      ],
      "id": "haHi8oQRuJ61"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMowMVqfuJ63"
      },
      "source": [
        "$$\n",
        "$$"
      ],
      "id": "HMowMVqfuJ63"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sezxd-wWuJ63"
      },
      "source": [
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!---->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
        "<!--\n",
        "\n",
        "-->"
      ],
      "id": "sezxd-wWuJ63"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg0iuDaNuJ64"
      },
      "source": [
        "## Code Reuse with Fynesse\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/osm-code-reuse-fynesse.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/osm-code-reuse-fynesse.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "{We will be reusing some of the functions we created in the first\n",
        "practical. This demonstrates one of the key principles of data science:\n",
        "building reusable code libraries that can be applied across multiple\n",
        "projects."
      ],
      "id": "Dg0iuDaNuJ64"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ra0VA2UbuJ65"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install osmnx"
      ],
      "id": "Ra0VA2UbuJ65"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGCne-gquJ67"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Install your Fyness library, and run code to show its available."
      ],
      "id": "HGCne-gquJ67"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ziGrvujeuJ67",
        "outputId": "8de4f0ac-ab29-49f8-fced-a1859d5a16bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fynesse_mlfc'...\n",
            "remote: Enumerating objects: 345, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 345 (delta 81), reused 6 (delta 6), pack-reused 223 (from 2)\u001b[K\n",
            "Receiving objects: 100% (345/345), 2.20 MiB | 11.06 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n"
          ]
        }
      ],
      "source": [
        "# Write your answer to Exercise 1 here\n",
        "\n",
        "import shutil\n",
        "shutil.rmtree(\"/content/fynesse_mlfc\", ignore_errors=True)\n",
        "!git clone https://github.com/silprosa/fynesse_mlfc.git\n",
        "import os, subprocess, importlib, sys\n",
        "sys.path.append(\"/content/fynesse_mlfc\")\n",
        "import fynesse\n",
        "\n"
      ],
      "id": "ziGrvujeuJ67"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "23IPV_-UuJ68",
        "outputId": "22539592-a0f7-4d51-8d72-0b943f8b1e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InsufficientResponseError",
          "evalue": "No matching features. Check query location, tags, and log.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInsufficientResponseError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4282494489.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example: Plot a city map using your reusable function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfynesse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_city_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nyeri, Kenya'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.4371\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36.9580\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/fynesse_mlfc/fynesse/assess.py\u001b[0m in \u001b[0;36mplot_city_map\u001b[0;34m(place_name, latitude, longitude, box_size_km, poi_tags)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mshops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_from_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"shop\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mroads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_from_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"highway\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mwaterways\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_from_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"waterway\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mnatural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_from_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"natural\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtourism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_from_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"tourism\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/osmnx/features.py\u001b[0m in \u001b[0;36mfeatures_from_bbox\u001b[0;34m(bbox, tags)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# convert bbox to polygon then create GeoDataFrame of features within it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mpolygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils_geo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_to_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures_from_polygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/osmnx/features.py\u001b[0m in \u001b[0;36mfeatures_from_polygon\u001b[0;34m(polygon, tags)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# retrieve the data from Overpass then turn it into a GeoDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mresponse_jsons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_overpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_overpass_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_create_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_jsons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/osmnx/features.py\u001b[0m in \u001b[0;36m_create_gdf\u001b[0;34m(response_jsons, polygon, tags)\u001b[0m\n\u001b[1;32m    418\u001b[0m     gdf = (\n\u001b[1;32m    419\u001b[0m         gpd.GeoDataFrame(\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_process_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mgeometry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_crs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/osmnx/features.py\u001b[0m in \u001b[0;36m_process_features\u001b[0;34m(elements, query_tag_keys)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"No matching features. Check query location, tags, and log.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInsufficientResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInsufficientResponseError\u001b[0m: No matching features. Check query location, tags, and log."
          ]
        }
      ],
      "source": [
        "# Example: Plot a city map using your reusable function\n",
        "fynesse.assess.plot_city_map('Nyeri, Kenya', -0.4371, 36.9580, 2)"
      ],
      "id": "23IPV_-UuJ68"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUdozKjJuJ69"
      },
      "source": [
        "## DSAIL-Porini Dataset\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Head over to https://data.mendeley.com/datasets/6mhrhn7rxc/6 to explore\n",
        "the DSAIL-Porini dataset. This dataset contains camera trap images and\n",
        "annotations from Kenya, providing rich information about wildlife\n",
        "patterns and behavior.\n",
        "\n",
        "Locate the `camera_trap_dataset_annotation.xlsx` file and make it\n",
        "available in this notebook."
      ],
      "id": "CUdozKjJuJ69"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb6xxsLCuJ69"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "id": "sb6xxsLCuJ69"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k25HleizuJ69"
      },
      "outputs": [],
      "source": [
        "def download_if_not_exists(url, filepath):\n",
        "    \"\"\"Download file if it doesn't exist locally\"\"\"\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"File already exists: {filepath}\")\n",
        "    else:\n",
        "        print(f\"Downloading: {url}\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"Downloaded to: {filepath}\")\n",
        "    return filepath"
      ],
      "id": "k25HleizuJ69"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApBPqCW1uJ6-"
      },
      "outputs": [],
      "source": [
        "# Download the DSAIL-Porini dataset\n",
        "porini_file = download_if_not_exists(\n",
        "    'https://data.mendeley.com/public-files/datasets/6mhrhn7rxc/files/641e83c9-16a3-485c-b247-b5701f8a5540/file_downloaded',\n",
        "    'camera_trap_dataset_annotation.xlsx'\n",
        ")"
      ],
      "id": "ApBPqCW1uJ6-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwPCt1-KuJ6-"
      },
      "outputs": [],
      "source": [
        "porini_df = pd.read_excel(porini_file)\n",
        "porini_df.head()"
      ],
      "id": "LwPCt1-KuJ6-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_b4qm2NuJ6_"
      },
      "source": [
        "## Joining Datasets\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-joining.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-joining.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "W_b4qm2NuJ6_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylNUrFTYuJ6_"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Geospatial data is particularly useful because it is the most common\n",
        "index in the world, over which so many datasets can be joined. Find the\n",
        "coordiante information in the dataset, and plot it on top of an OSM map.\n",
        "\n",
        "You may want to deduplicate the coordinates before you plot!"
      ],
      "id": "ylNUrFTYuJ6_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6snK2LUuJ6_"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 2 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "o6snK2LUuJ6_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQIJYuOXuJ7A"
      },
      "source": [
        "<!-- Dsail Porini Address -->"
      ],
      "id": "aQIJYuOXuJ7A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG5qfAcGuJ7A"
      },
      "source": [
        "## Sighting Predictions\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-preprocessing.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-preprocessing.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We will use the dataset to create a simple prediction model for the\n",
        "likelihood of animal sightings.\n",
        "\n",
        "Let’s follow a minimal example of the Access-Assess-Address framework!\n",
        "\n",
        "Reminder about Neil’s article on the framework\n",
        "[here](https://inverseprobability.com/talks/notes/access-assess-address-a-pipeline-for-automated-data-science.html)."
      ],
      "id": "dG5qfAcGuJ7A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6C15hn2uJ7A"
      },
      "source": [
        "### Access\n",
        "\n",
        "Access is already done, partly years ago by the DSAIL team, and two\n",
        "cells above by us. Example tasks within access would be:\n",
        "\n",
        "-   Setting up the cameras in the woods (done)\n",
        "-   Collecting the pictures (done)\n",
        "-   Labeling the dataset (done)\n",
        "-   Making the excel file online accessible (done)\n",
        "-   Downloading the file (done just now)}"
      ],
      "id": "y6C15hn2uJ7A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df5xfwYvuJ7B"
      },
      "outputs": [],
      "source": [
        "porini_df.head()"
      ],
      "id": "df5xfwYvuJ7B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F1zWF1cuJ7B"
      },
      "source": [
        "### Assess\n",
        "\n",
        "Have a look at the dataset for any issues that could stop us from being\n",
        "able to cleanly analyse it.\n",
        "\n",
        "Some issues:\n",
        "\n",
        "-   Timestamps not readilly available. Hidden in image filenames.\n",
        "-   No timestamps available for one of the cameras.\n",
        "-   No Camera ID, but can be deduced from coordinates.\n",
        "\n",
        "Decide how it would be best to address these and potentially other\n",
        "issues with the data.\n",
        "\n",
        "We would like an output dataframe that has a column for counts each\n",
        "animal was spotted by each camera, and rows for each day in the\n",
        "available range. You might want to use this opportunity to practice\n",
        "[Pandas\n",
        "MultiIndex](https://pandas.pydata.org/docs/user_guide/advanced.html)."
      ],
      "id": "0F1zWF1cuJ7B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaEI5nWkuJ7B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "id": "PaEI5nWkuJ7B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqdiJeBkuJ7B"
      },
      "outputs": [],
      "source": [
        "# Copy original\n",
        "df = porini_df.copy()\n",
        "\n",
        "# Normalize species and parse counts\n",
        "df[\"Species\"] = df[\"Species\"].astype(str).str.strip()\n",
        "\n",
        "# Extract timestamp from filename\n",
        "pat = re.compile(r\"(\\d{4})-(\\d{2})-(\\d{2})-(\\d{2})-(\\d{2})-(\\d{2})\")\n",
        "def parse_ts(name):\n",
        "    m = pat.search(str(name))\n",
        "    if not m:\n",
        "        return pd.NaT\n",
        "    y, M, d, h, m_, s = map(int, m.groups())\n",
        "    return pd.Timestamp(y, M, d, h, m_, s)\n",
        "\n",
        "df[\"timestamp\"] = df[\"Filename\"].map(parse_ts)\n",
        "df[\"date\"] = df[\"timestamp\"].dt.date\n",
        "\n",
        "# Camera ID from rounded lat/lon\n",
        "df[\"Latitude\"] = df[\"Latitude\"].round(4)\n",
        "df[\"Longitude\"] = df[\"Longitude\"].round(4)\n",
        "coord_key = df[\"Latitude\"].astype(str) + \",\" + df[\"Longitude\"].astype(str)\n",
        "codes, _ = pd.factorize(coord_key)\n",
        "df[\"camera_id\"] = pd.Series(codes).map(lambda i: f\"C{int(i)+1:03d}\")\n",
        "\n",
        "# Extract camera coordinates dictionary (rounded)\n",
        "camera_coords = (\n",
        "    df.drop_duplicates(subset=\"camera_id\")[[\"camera_id\", \"Latitude\", \"Longitude\"]]\n",
        "      .set_index(\"camera_id\")\n",
        "      .sort_index()\n",
        "      .apply(tuple, axis=1)\n",
        "      .to_dict()\n",
        ")\n",
        "\n",
        "# Group and count: number of pictures per species per camera per day\n",
        "daily = (\n",
        "    df.dropna(subset=[\"date\"])\n",
        "      .groupby([\"date\", \"camera_id\", \"Species\"])\n",
        "      .size()\n",
        "      .reset_index(name=\"photo_count\")\n",
        "      .pivot_table(index=\"date\", columns=[\"camera_id\", \"Species\"], values=\"photo_count\", aggfunc=\"sum\")\n",
        "      .fillna(0)\n",
        "      .astype(int)\n",
        "      .sort_index()\n",
        ")\n",
        "\n",
        "# Fill missing dates\n",
        "if not daily.empty:\n",
        "    full_idx = pd.date_range(start=daily.index.min(), end=daily.index.max(), freq=\"D\").date\n",
        "    daily = daily.reindex(full_idx).fillna(0).astype(int)\n",
        "    daily.index.name = \"date\"\n",
        "\n",
        "print(camera_coords)\n",
        "daily.tail()"
      ],
      "id": "cqdiJeBkuJ7B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVu0IjlouJ7C"
      },
      "source": [
        "Huh, looks like we have some more issues.\n",
        "\n",
        "-   “Impala, Monkey” is not a species - should be counted towards two!\n",
        "-   “Can’t Tell” shouldn’t be a species at all.\n",
        "-   Some columns don’t exist (eg. `C011` has no `ZEBRA`). Let’s just\n",
        "    fill them with zeros.\n",
        "\n",
        "Additionally, there probably weren’t `1577` impalas spotted on Christmas\n",
        "Eve 2021. This is a result of burst shots repetitively capturing the\n",
        "same animal. For now, let’s just treat the data as binary, whether at\n",
        "least one photo was taken on that day."
      ],
      "id": "PVu0IjlouJ7C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3seckxg4uJ7C"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Use the cell below to implement the changes discussed above, and\n",
        "potentially additional issues."
      ],
      "id": "3seckxg4uJ7C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjYy7r4IuJ7D"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 3 here\n",
        "\n",
        "\n",
        "daily_bin = daily.copy()\n",
        "# Step 1: Flatten the multi-index and reshape the dataframe\n",
        "\n",
        "daily_bin.columns = pd.MultiIndex.from_tuples(daily_bin.columns)\n",
        "\n",
        "# Step 2: Create a new clean dataframe\n",
        "binary_rows = []\n",
        "\n",
        "for (cam, species_str), series in daily_bin.items():\n",
        "    # Split species (e.g. \"IMPALA, MONKEY\") into a list of individual species\n",
        "    # ignore the \"CAN'T TELL\" species\n",
        "    species_list = [] #TODO\n",
        "\n",
        "    for species in species_list:\n",
        "\n",
        "      col = pd.Series(series, index=series.index)\n",
        "      # Convert every value to 1 if any sightings, otherwise 0\n",
        "      col_bin =\n",
        "      binary_rows.append((cam, species, col_bin))\n",
        "\n",
        "# Step 3: Rebuild dataframe as binary_df\n",
        "\n",
        "binary_df = pd.DataFrame({\n",
        "    (cam, species): values\n",
        "    for cam, species, values in binary_rows\n",
        "}, index=daily_bin.index)\n",
        "\n",
        "# Step 4: Create MultiIndex and\n",
        "binary_df.columns = pd.MultiIndex.from_tuples(binary_df.columns)\n",
        "binary_df = binary_df.sort_index(axis=1, level=[0, 1])\n",
        "\n",
        "# Step 5: Ensure all possible (camera, species) pairs exist\n",
        "\n",
        "# Get all unique cameras and species used across all rows and store as a list\n",
        "all_cameras = [] #TODO\n",
        "all_species = [] #TODO\n",
        "\n",
        "# Build full column MultiIndex\n",
        "full_columns = pd.MultiIndex.from_product([all_cameras, all_species], names=[\"camera_id\", \"Species\"])\n",
        "\n",
        "# Reindex to include all possible combinations, fill missing with 0\n",
        "binary_df = binary_df.reindex(columns=full_columns, fill_value=0)\n",
        "\n",
        "binary_df.tail()\n",
        "\n"
      ],
      "id": "fjYy7r4IuJ7D"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz2Rx-HQuJ7D"
      },
      "source": [
        "## Statistical Analysis of Sighting Patterns\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-probability-analysis.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-probability-analysis.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "Fz2Rx-HQuJ7D"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvjNiEqXuJ7E"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "Now let’s create a simple prediction system for whether a specific\n",
        "`camera` captured a `species` on a given `date`. Let’s use the whole\n",
        "dataset, except the prediction target date.\n",
        "\n",
        "Before we jump into addressing the question, let’s further assess the\n",
        "data. Calculate and plot average probabilities for dates, species, and\n",
        "cameras. You may want to implement some smoothing over dates, or group\n",
        "them into longer ranges."
      ],
      "id": "qvjNiEqXuJ7E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwPu7R9auJ7E"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 4 here\n",
        "\n",
        "\n",
        "if not isinstance(df.index, (pd.DatetimeIndex, pd.PeriodIndex, pd.TimedeltaIndex)):\n",
        "        df = df.copy()\n",
        "        df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
        "df = df.sort_index()\n",
        "\n",
        "# raw daily mean across all (camera, species)\n",
        "avg_by_date_raw = df.mean(axis=1)\n",
        "\n",
        "\n",
        "# set and apply smooth frequency\n",
        "smooth_freq = \"ME\" # Monthly average, \"YE\" would be yearly\n",
        "avg_by_date_smooth = avg_by_date_raw.resample(smooth_freq).mean()\n",
        "\n",
        "# plot raw + smoothed\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(avg_by_date_raw.index, avg_by_date_raw.values, alpha=0.4, label=\"Daily (raw)\")\n",
        "plt.plot(avg_by_date_smooth.index, avg_by_date_smooth.values, linewidth=2, label=f\"Smoothed (Monthly Average)\")\n",
        "plt.title(\"Average Sighting Probability Over Time\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"Probability\"); plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Print these commands to help you understand what they do\n",
        "#print(binary_df.index)\n",
        "#print(binary_df.mean(axis=0))\n",
        "#print(binary_df.mean(axis=0).groupby(level=1).mean())\n",
        "\n",
        "#TODO Plot species and camera averages\n",
        "\n"
      ],
      "id": "SwPu7R9auJ7E"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQNsEue4uJ7E"
      },
      "source": [
        "Exercise 3 extension: which of these relationships that you found are\n",
        "statistically significant?"
      ],
      "id": "fQNsEue4uJ7E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cpD69tSuJ7F"
      },
      "outputs": [],
      "source": [
        "# TODO Exercise 3 Extended"
      ],
      "id": "-cpD69tSuJ7F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfdbG63quJ7F"
      },
      "source": [
        "## Address: Naive Bayesian Prediction Model\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-naive-bayes.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-naive-bayes.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Using the data we collected in the Access stage and understood in\n",
        "Assess, we can now Address our question, and create a naive Bayesian\n",
        "classification model for predicting the probability of a camera sighting\n",
        "a species on a given day.\n",
        "\n",
        "$$\n",
        "\\text{P}(1 \\mid c, s, d) = \\frac{P(1) \\cdot P(c \\mid 1) \\cdot P(s \\mid 1) \\cdot P(d \\mid 1)}{P(c,s,d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Using Bayes' rule:} \\quad P(c \\mid 1) = \\frac{P(1 \\mid c) \\cdot P(c)}{P(1)} \\quad \\text{(and similarly for } s, d\\text{)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow \\text{P}(1 \\mid c, s, d) = \\frac{P(1) \\cdot \\frac{P(1 \\mid c) \\cdot P(c)}{P(1)} \\cdot \\frac{P(1 \\mid s) \\cdot P(s)}{P(1)} \\cdot \\frac{P(1 \\mid d) \\cdot P(d)}{P(1)}}{P(c,s,d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\frac{P(1 \\mid c) \\cdot P(1 \\mid s) \\cdot P(1 \\mid d) \\cdot P(c) \\cdot P(s) \\cdot P(d)}{P(1)^2 \\cdot P(c,s,d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Assuming independence:}\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(1 \\mid c,s,d)=\\frac{P(1 \\mid c) \\cdot P(1 \\mid s) \\cdot P(1 \\mid d)}{P(1)^2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "&c = \\text{camera ID (e.g., C001)} \\\\\n",
        "&s = \\text{species (e.g., IMPALA)} \\\\\n",
        "&d = \\text{smoothed date (e.g., month, or Gaussian-filtered day)}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "id": "MfdbG63quJ7F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufoXJFtGuJ7F"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "Implement the model below."
      ],
      "id": "ufoXJFtGuJ7F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-JLyzPDuJ7G"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 5 here\n",
        "\n",
        "\n",
        "from typing import Union\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date as DateType\n",
        "\n",
        "def bayes_sighting_probability(df, camera, species, date) -> float:\n",
        "    \"\"\"\n",
        "    Removes a specific observation and estimates the probability of sighting\n",
        "    a given species at a given camera on a specific date.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with MultiIndex columns (camera, species) and datetime.date index.\n",
        "        camera (str): Camera ID (e.g. 'C001').\n",
        "        species (str): Species name (e.g. 'IMPALA').\n",
        "        date (str or datetime.date or pd.Timestamp): Date of the observation.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated sighting probability - TODO.\n",
        "    \"\"\"\n",
        "    if isinstance(date, str) or isinstance(date, pd.Timestamp):\n",
        "        date = pd.to_datetime(date).date()\n",
        "\n",
        "    df_blind = df.copy()\n",
        "    df_blind.loc[date, (camera, species)] = None\n",
        "\n",
        "    #TODO Exercise 4\n",
        "\n",
        "    raise NotImplementedError(\"Prediction logic not implemented yet.\")\n",
        "\n",
        "\n"
      ],
      "id": "8-JLyzPDuJ7G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maLv92dNuJ7G"
      },
      "source": [
        "Well done! We should now have a working Access-Assess-Address data\n",
        "science pipeline! Let’s see how it does."
      ],
      "id": "maLv92dNuJ7G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbPmzo0BuJ7G"
      },
      "outputs": [],
      "source": [
        "#"
      ],
      "id": "lbPmzo0BuJ7G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RNgk2hmuJ7G"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "The data is extremely sparse, with less than 1% of values being `1`.\n",
        "This is a challenge, as checking naive accuracy would make always-zero a\n",
        "very very good predictor.\n",
        "\n",
        "Let’s evaluate our prediction system using `log-loss`\n",
        "i.e. `cross-entropy`:\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1}^{N}\n",
        "\\Big[\n",
        "    y_i \\, \\log(\\hat{p}_i) + (1 - y_i) \\, \\log(1 - \\hat{p}_i)\n",
        "\\Big]\n",
        "$$"
      ],
      "id": "8RNgk2hmuJ7G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No-YaHe5uJ7H"
      },
      "source": [
        "### Exercise 6\n",
        "\n",
        "Implement the loss function below."
      ],
      "id": "No-YaHe5uJ7H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBP_scuZuJ7L"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 6 here\n",
        "\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    #TODO Exercise 5\n",
        "    raise NotImplementedError(\"Cross entropy not implemented yet.\")\n",
        "\n",
        "def evaluate_prediction_system(df, your_function, max_samples=1000):\n",
        "    # Randomly sample up to 1000, if full evaluation taking too long\n",
        "    np.random.seed(42)\n",
        "    coords = [(date, camera, species) for date in df.index for (camera, species) in df.columns]\n",
        "    if len(coords) > max_samples:\n",
        "        coords = np.random.choice(len(coords), size=max_samples, replace=False)\n",
        "        coords = [coords[i] if isinstance(coords[i], tuple) else\n",
        "                  [(date, camera, species) for date in df.index for (camera, species) in df.columns][coords[i]]\n",
        "                  for i in range(len(coords))]\n",
        "    else:\n",
        "        coords = coords\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for date, camera, species in coords:\n",
        "        value = df.loc[date, (camera, species)]\n",
        "        y_true.append(value)\n",
        "        prob = your_function(df, camera, species, date)\n",
        "        y_pred.append(prob)\n",
        "\n",
        "    return cross_entropy(y_true, y_pred)\n",
        "\n",
        "# Let's pass our function to be evaluated. This could take quite some time if your function is complex.\n",
        "evaluate_prediction_system(binary_df, bayes_sighting_probability)\n",
        "\n"
      ],
      "id": "rBP_scuZuJ7L"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-dSh_hDuJ7M"
      },
      "source": [
        "For reference, predicting a constant probability (eg. 0.5%) gives a loss\n",
        "of around 0.026. This should be the benchmark number we want to improve\n",
        "on. If your model does better than that, well done!\n",
        "\n",
        "*Note: our approach included look-ahead bias - making predictions based\n",
        "on data that we would not have access to at the time. For real-life\n",
        "deployment, we would need to limit our training data to before\n",
        "individual test cases.*"
      ],
      "id": "w-dSh_hDuJ7M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZKFktAbuJ7M"
      },
      "source": [
        "## Improving the Method: Correlated Variables\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-correlation-analysis-improvements.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-correlation-analysis-improvements.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "The model above was quite simplified, and it disregarded any\n",
        "correlations between the three variables. Since cameras are close to\n",
        "each other, maybe they are more likely to capture the same animals on\n",
        "the same day? Maybe some animals like or avoid some areas, or some other\n",
        "animals? If any of the above is true, we can’t really be using simple\n",
        "Bayes’ rule classification."
      ],
      "id": "iZKFktAbuJ7M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmwMtp1CuJ7M"
      },
      "source": [
        "### Exercise 7\n",
        "\n",
        "Analyse the data again to find the strongest relationships which can be\n",
        "used to improve predictions. Plot correlation matrices and other helpful\n",
        "charts.\n",
        "\n",
        "Have a short read through the [DSAIL-Porini\n",
        "paper](https://www.sciencedirect.com/science/article/pii/S2352340922010666)\n",
        "for inspiration about other probability analyses that can be done here."
      ],
      "id": "EmwMtp1CuJ7M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HnFXVNTuJ7N"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 7 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "1HnFXVNTuJ7N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoT-9NbMuJ7N"
      },
      "source": [
        "Exercise Extension: Use what you found to improve your prediction model,\n",
        "and compare it against the previous one."
      ],
      "id": "EoT-9NbMuJ7N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PHySqSRuJ7N"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date as DateType\n",
        "\n",
        "def improved_sighting_probability(df, camera, species, date) -> float:\n",
        "    \"\"\"\n",
        "    Removes a specific observation and estimates the probability of sighting\n",
        "    a given species at a given camera on a specific date.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with MultiIndex columns (camera, species) and datetime.date index.\n",
        "        camera (str): Camera ID (e.g. 'C001').\n",
        "        species (str): Species name (e.g. 'IMPALA').\n",
        "        date (str or datetime.date or pd.Timestamp): Date of the observation.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated sighting probability - TODO.\n",
        "    \"\"\"\n",
        "    if isinstance(date, str) or isinstance(date, pd.Timestamp):\n",
        "        date = pd.to_datetime(date).date()\n",
        "\n",
        "    df_blind = df.copy()\n",
        "    df_blind.loc[date, (camera, species)] = None\n",
        "\n",
        "    #TODO Exercise 6 Extended\n",
        "\n",
        "    raise NotImplementedError(\"Prediction logic not implemented yet.\")"
      ],
      "id": "1PHySqSRuJ7N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NDOotUuJ7N"
      },
      "source": [
        "## Extended Exercises\n",
        "\n",
        "We didn’t use all of the available data when we just classified days as\n",
        "“sighting” or “no sighting.” Extend your analysis to include all the\n",
        "information in the file, like numbers of sightings, and numbers of\n",
        "animals in the photos.\n",
        "\n",
        "This will be quite challenging due to burst shots - assess the dataset\n",
        "and come up with a good definition of what a burst is, and a data\n",
        "structure that has the information you chose as important.\n",
        "\n",
        "Example burst data: - Camera, Date, Species - Time Start, Time End -\n",
        "Number of photos - Average/most animals in a photo\n",
        "\n",
        "*Particular challenge around deduplicating multi-species sightings.*"
      ],
      "id": "i_NDOotUuJ7N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thJAqyIQuJ7O"
      },
      "source": [
        "### Exercise 8\n",
        "\n",
        "Use this additional data and repeat the analysis you did above. Aim to\n",
        "further improve predictions and write a new function like\n",
        "`burst_sighting_probability('C001', 'IMPALA', '2021-12-24')`."
      ],
      "id": "thJAqyIQuJ7O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFLfds_muJ7O"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 8 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "AFLfds_muJ7O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZNrYaxKuJ7O"
      },
      "source": [
        "### Exercise 9\n",
        "\n",
        "Compare the results and note the improvement (or lack thereof) against\n",
        "the two previous prediction functions you created."
      ],
      "id": "PZNrYaxKuJ7O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4XdXZbquJ7P"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 9 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "-4XdXZbquJ7P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zozn_IlpuJ7P"
      },
      "source": [
        "### Exercise 10\n",
        "\n",
        "What other benefits does your new system provide? Can you modify it to\n",
        "provide more predictions, like expected number of sightings, number of\n",
        "animals?"
      ],
      "id": "zozn_IlpuJ7P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnuM-CKxuJ7P"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 10 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "UnuM-CKxuJ7P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t46qoUWuJ7P"
      },
      "source": [
        "## Database Integration with SQLite\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-sqlite-database-creation.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-sqlite-database-creation.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Throughout the course you will work with various datasets and data\n",
        "formats. An SQL database is one of the most common ways to store large\n",
        "amounts of data. We recognise that many of you may be familiar with this\n",
        "already, but let’s use this example to build a small toy database of\n",
        "animal sightings based on the excel file and the dataframes we created."
      ],
      "id": "1t46qoUWuJ7P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50a-WJc3uJ7Q"
      },
      "source": [
        "### Exercise 11\n",
        "\n",
        "-   Create a local database (eg. `sqlite3`).\n",
        "-   Add a table with animal sighting data.\n",
        "-   Add a table with camera coordinates data.\n",
        "-   Set indices on columns you might search by (eg. `CameraID`, `Date`).\n",
        "    Make sure the index types make sense!\n",
        "-   Look into multi column indices, and set one on `Latitude` and\n",
        "    `Longitude`.\n",
        "-   Demonstrate success with a couple SQL queries, eg. counting `IMPALA`\n",
        "    sightings within a `200m` square around `-0.3866, 36.9649`.\n",
        "\n",
        "Helpful links:\n",
        "\n",
        "[SQL Intro, Creating Tables, Indices,\n",
        "Joins](https://www.w3schools.com/sql/sql_intro.asp)\n",
        "\n",
        "[Multi-Column\n",
        "Indices](https://stackoverflow.com/questions/179085/multiple-indexes-vs-multi-column-indexes)\n",
        "\n",
        "Remember to include reusable code from this and previous exercises in\n",
        "your Fynesse library!"
      ],
      "id": "50a-WJc3uJ7Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P8uS0AwuJ7Q"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 11 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "9P8uS0AwuJ7Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxFBtiHGuJ7R"
      },
      "source": [
        "## Extended Analysis: Burst Detection\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-burst-detection-analysis.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-burst-detection-analysis.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We didn’t use all of the available data when we just classified days as\n",
        "“sighting” or “no sighting.” Camera traps often capture “burst”\n",
        "sequences - multiple photos taken in rapid succession when motion is\n",
        "detected. Understanding and properly handling these bursts can provide\n",
        "richer information about animal behavior.\n",
        "\n",
        "This extended analysis is quite challenging due to the complexity of\n",
        "burst detection and multi-species deduplication."
      ],
      "id": "xxFBtiHGuJ7R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPDb7I48uJ7R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta"
      ],
      "id": "uPDb7I48uJ7R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pECALhNYuJ7S"
      },
      "outputs": [],
      "source": [
        "# Define what constitutes a \"burst\"\n",
        "def detect_bursts(df, time_threshold_minutes=5, min_photos=2):\n",
        "    \"\"\"\n",
        "    Detect photo bursts in camera trap data\n",
        "\n",
        "    Parameters:\n",
        "        df: DataFrame with timestamp and camera_id columns\n",
        "        time_threshold_minutes: Photos within this time are considered same burst\n",
        "        min_photos: Minimum photos to constitute a burst\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with burst information\n",
        "    \"\"\"\n",
        "    bursts = []\n",
        "\n",
        "    # Group by camera and species\n",
        "    for (camera, species), group in df.groupby(['camera_id', 'Species']):\n",
        "        # Sort by timestamp\n",
        "        group_sorted = group.dropna(subset=['timestamp']).sort_values('timestamp')\n",
        "\n",
        "        if len(group_sorted) < min_photos:\n",
        "            continue\n",
        "\n",
        "        # Identify bursts using time gaps\n",
        "        time_diffs = group_sorted['timestamp'].diff()\n",
        "        burst_breaks = time_diffs > pd.Timedelta(minutes=time_threshold_minutes)\n",
        "        burst_ids = burst_breaks.cumsum()\n",
        "\n",
        "        # Process each burst\n",
        "        for burst_id, burst_group in group_sorted.groupby(burst_ids):\n",
        "            if len(burst_group) >= min_photos:\n",
        "                burst_info = {\n",
        "                    'camera_id': camera,\n",
        "                    'species': species,\n",
        "                    'burst_start': burst_group['timestamp'].min(),\n",
        "                    'burst_end': burst_group['timestamp'].max(),\n",
        "                    'duration_seconds': (burst_group['timestamp'].max() -\n",
        "                                       burst_group['timestamp'].min()).total_seconds(),\n",
        "                    'num_photos': len(burst_group),\n",
        "                    'date': burst_group['timestamp'].min().date()\n",
        "                }\n",
        "                bursts.append(burst_info)\n",
        "\n",
        "    return pd.DataFrame(bursts)\n",
        "\n",
        "# Apply burst detection to our data (if we have timestamp data)\n",
        "if 'df' in locals() and 'timestamp' in df.columns:\n",
        "    burst_data = detect_bursts(df)\n",
        "\n",
        "    print(f\"Detected {len(burst_data)} bursts\")\n",
        "    if len(burst_data) > 0:\n",
        "        print(\"\\nBurst statistics:\")\n",
        "        print(f\"  Average photos per burst: {burst_data['num_photos'].mean():.1f}\")\n",
        "        print(f\"  Average burst duration: {burst_data['duration_seconds'].mean():.1f} seconds\")\n",
        "        print(f\"  Longest burst: {burst_data['num_photos'].max()} photos\")\n",
        "\n",
        "        # Show burst distribution by species\n",
        "        burst_by_species = burst_data.groupby('species').agg({\n",
        "            'num_photos': ['count', 'mean'],\n",
        "            'duration_seconds': 'mean'\n",
        "        }).round(2)\n",
        "        burst_by_species.columns = ['Total_Bursts', 'Avg_Photos_per_Burst', 'Avg_Duration_Seconds']\n",
        "        print(\"\\nBurst patterns by species:\")\n",
        "        print(burst_by_species)\n",
        "else:\n",
        "    print(\"Timestamp data not available for burst analysis\")"
      ],
      "id": "pECALhNYuJ7S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS7wDlRtuJ7S"
      },
      "outputs": [],
      "source": [
        "# Advanced analysis: Multi-species burst handling\n",
        "def analyze_multispecies_interactions(burst_data, time_window_minutes=10):\n",
        "    \"\"\"\n",
        "    Analyze cases where multiple species appear in close temporal/spatial proximity\n",
        "    \"\"\"\n",
        "    if len(burst_data) == 0:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    interactions = []\n",
        "\n",
        "    # Group bursts by camera and date\n",
        "    for (camera, date), day_bursts in burst_data.groupby(['camera_id', 'date']):\n",
        "        day_bursts_sorted = day_bursts.sort_values('burst_start')\n",
        "\n",
        "        # Look for overlapping or closely timed bursts of different species\n",
        "        for i in range(len(day_bursts_sorted)):\n",
        "            burst1 = day_bursts_sorted.iloc[i]\n",
        "\n",
        "            for j in range(i+1, len(day_bursts_sorted)):\n",
        "                burst2 = day_bursts_sorted.iloc[j]\n",
        "\n",
        "                # Check if bursts are close in time\n",
        "                time_gap = (burst2['burst_start'] - burst1['burst_end']).total_seconds()\n",
        "\n",
        "                if time_gap <= time_window_minutes * 60 and burst1['species'] != burst2['species']:\n",
        "                    interaction = {\n",
        "                        'camera_id': camera,\n",
        "                        'date': date,\n",
        "                        'species_1': burst1['species'],\n",
        "                        'species_2': burst2['species'],\n",
        "                        'time_gap_seconds': time_gap,\n",
        "                        'interaction_type': 'sequential' if time_gap > 0 else 'overlapping'\n",
        "                    }\n",
        "                    interactions.append(interaction)\n",
        "\n",
        "    return pd.DataFrame(interactions)\n",
        "\n",
        "# Analyze species interactions\n",
        "if 'burst_data' in locals() and len(burst_data) > 0:\n",
        "    interactions = analyze_multispecies_interactions(burst_data)\n",
        "\n",
        "    if len(interactions) > 0:\n",
        "        print(f\"\\nFound {len(interactions)} potential species interactions\")\n",
        "\n",
        "        # Most common species pairs\n",
        "        species_pairs = interactions.groupby(['species_1', 'species_2']).size().sort_values(ascending=False)\n",
        "        print(\"\\nMost frequent species interactions:\")\n",
        "        print(species_pairs.head())\n",
        "\n",
        "        # Temporal patterns\n",
        "        avg_gap = interactions['time_gap_seconds'].mean()\n",
        "        print(f\"\\nAverage time gap between species: {avg_gap:.1f} seconds\")\n",
        "    else:\n",
        "        print(\"\\nNo close species interactions detected\")\n",
        "else:\n",
        "    print(\"Burst data not available for interaction analysis\")"
      ],
      "id": "HS7wDlRtuJ7S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UbWD6nzuJ7T"
      },
      "source": [
        "This extended analysis demonstrates how camera trap data can be mined\n",
        "for complex ecological insights. Burst patterns can reveal:\n",
        "\n",
        "-   **Feeding behavior**: Long bursts might indicate feeding sites\n",
        "-   **Group dynamics**: Multiple animals in quick succession\n",
        "-   **Species interactions**: Temporal associations between different\n",
        "    species\n",
        "-   **Individual identification**: Consistent burst patterns might help\n",
        "    identify individuals\n",
        "\n",
        "The challenge lies in balancing detail with computational complexity,\n",
        "and in handling the inherent uncertainty in automated image analysis.\n",
        "\n",
        "End of Practical 3\n",
        "\n",
        "     _______  __   __  _______  __    _  ___   _  _______  __\n",
        "    |       ||  | |  ||   _   ||  |  | ||   | | ||       ||  |\n",
        "    |_     _||  |_|  ||  |_|  ||   |_| ||   |_| ||  _____||  |\n",
        "      |   |  |       ||       ||       ||      _|| |_____ |  |\n",
        "      |   |  |       ||       ||  _    ||     |_ |_____  ||__|\n",
        "      |   |  |   _   ||   _   || | |   ||    _  | _____| | __\n",
        "      |___|  |__| |__||__| |__||_|  |__||___| |_||_______||__|\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "## References"
      ],
      "id": "6UbWD6nzuJ7T"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}