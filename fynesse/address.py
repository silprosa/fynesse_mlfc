"""
Address module for the fynesse framework.

This module handles question addressing functionality including:
- Statistical analysis
- Predictive modeling
- Data visualization for decision-making
- Dashboard creation
"""
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import numpy as np

def train_location_classifier(X_train, y_train, model_type='logistic'):
    """
    Train a classifier to predict location based on geographic features.
    
    Args:
        X_train (numpy.ndarray): Training features
        y_train (numpy.ndarray): Training labels
        model_type (str): Type of classifier ('logistic' or 'random_forest')
        
    Returns:
        trained model
    """
    if model_type == 'logistic':
        model = LogisticRegression(random_state=42, max_iter=1000)
    elif model_type == 'random_forest':
        model = RandomForestClassifier(random_state=42, n_estimators=100)
    else:
        raise ValueError("Model type must be 'logistic' or 'random_forest'")
    
    model.fit(X_train, y_train)
    return model

def evaluate_classifier(model, X_test, y_test):
    """
    Evaluate classifier performance.
    
    Args:
        model: Trained classifier
        X_test (numpy.ndarray): Test features
        y_test (numpy.ndarray): Test labels
        
    Returns:
        dict: Evaluation metrics
    """
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    cm = confusion_matrix(y_test, y_pred)
    
    return {
        'accuracy': accuracy,
        'classification_report': report,
        'confusion_matrix': cm
    }

# Example usage function
def create_sample_data():
    """
    Create sample data for demonstration.
    
    Returns:
        tuple: (X, y) feature matrix and labels
    """
    # Sample data for two cities
    X_nyeri = np.array([
        [5, 10, 3, 2, 1, 21],  # Many amenities, few tourist spots
        [4, 8, 2, 1, 0, 15],
        [6, 12, 4, 3, 2, 27]
    ])
    
    X_cambridge = np.array([
        [15, 25, 8, 12, 6, 66],  # Many amenities and tourist spots
        [12, 20, 6, 10, 5, 53],
        [18, 30, 10, 15, 8, 81]
    ])
    
    X = np.vstack([X_nyeri, X_cambridge])
    y = np.array(['Nyeri'] * 3 + ['Cambridge'] * 3)
    
    return X, y
from typing import Any, Union
import pandas as pd
import logging

# Set up logging
logger = logging.getLogger(__name__)

# Here are some of the imports we might expect
# import sklearn.model_selection  as ms
# import sklearn.linear_model as lm
# import sklearn.svm as svm
# import sklearn.naive_bayes as naive_bayes
# import sklearn.tree as tree

# import GPy
# import torch
# import tensorflow as tf

# Or if it's a statistical analysis
# import scipy.stats


def analyze_data(data: Union[pd.DataFrame, Any]) -> dict[str, Any]:
    """
    Address a particular question that arises from the data.

    IMPLEMENTATION GUIDE FOR STUDENTS:
    ==================================

    1. REPLACE THIS FUNCTION WITH YOUR ANALYSIS CODE:
       - Perform statistical analysis on the data
       - Create visualizations to explore patterns
       - Build models to answer specific questions
       - Generate insights and recommendations

    2. ADD ERROR HANDLING:
       - Check if input data is valid and sufficient
       - Handle analysis failures gracefully
       - Validate analysis results

    3. ADD BASIC LOGGING:
       - Log analysis steps and progress
       - Log key findings and insights
       - Log any issues encountered

    4. EXAMPLE IMPLEMENTATION:
       if data is None or len(data) == 0:
           print("Error: No data available for analysis")
           return {}

       print("Starting data analysis...")
       # Your analysis code here
       results = {"sample_size": len(data), "analysis_complete": True}
       return results
    """
    logger.info("Starting data analysis")

    # Validate input data
    if data is None:
        logger.error("No data provided for analysis")
        print("Error: No data available for analysis")
        return {"error": "No data provided"}

    if len(data) == 0:
        logger.error("Empty dataset provided for analysis")
        print("Error: Empty dataset provided for analysis")
        return {"error": "Empty dataset"}

    logger.info(f"Analyzing data with {len(data)} rows, {len(data.columns)} columns")

    try:
        # STUDENT IMPLEMENTATION: Add your analysis code here

        # Example: Basic data summary
        results = {
            "sample_size": len(data),
            "columns": list(data.columns),
            "data_types": data.dtypes.to_dict(),
            "missing_values": data.isnull().sum().to_dict(),
            "analysis_complete": True,
        }

        # Example: Basic statistics (students should customize this)
        numeric_columns = data.select_dtypes(include=["number"]).columns
        if len(numeric_columns) > 0:
            results["numeric_summary"] = data[numeric_columns].describe().to_dict()

        logger.info("Data analysis completed successfully")
        print(f"Analysis completed. Sample size: {len(data)}")

        return results

    except Exception as e:
        logger.error(f"Error during data analysis: {e}")
        print(f"Error analyzing data: {e}")
        return {"error": str(e)}

def plot_odds_ratios(model, title="Odds Ratios", figsize=(10, 12)):
    """
    Extracts odds ratios with confidence intervals from a statsmodels logistic regression model 
    and plots them on a horizontal bar chart.

    Parameters:
    -----------
    model : statsmodels.discrete.discrete_model.BinaryResults
        Fitted logistic regression model.
    title : str, optional
        Title of the plot. Default is "Odds Ratios".
    figsize : tuple, optional
        Size of the matplotlib figure. Default is (10, 12).

    Returns:
    --------
    odds_ratios_df : pd.DataFrame
        DataFrame containing 2.5%, 97.5%, and OR values for each variable.
    """

    # Extract coefficients and confidence intervals
    params = model.params
    conf = model.conf_int()
    conf['OR'] = params
    conf.columns = ['2.5%', '97.5%', 'OR']

    # Convert from log-odds to odds ratios
    odds_ratios = np.exp(conf)

    # Sort for readability
    odds_ratios_df = odds_ratios.sort_values(by="OR", ascending=False)

    # Plot
    plt.figure(figsize=figsize)
    plt.barh(
        odds_ratios_df.index, 
        odds_ratios_df['OR'], 
        xerr=[
            odds_ratios_df['OR'] - odds_ratios_df['2.5%'],
            odds_ratios_df['97.5%'] - odds_ratios_df['OR']
        ],
        alpha=0.7
    )
    
    plt.axvline(x=1, color='red', linestyle='--')  # baseline
    plt.xlabel("Odds Ratio (log scale)")
    plt.title(title)
    plt.xscale("log")  # log scale for better visualization
    plt.tight_layout()
    plt.show()

    return odds_ratios_df
